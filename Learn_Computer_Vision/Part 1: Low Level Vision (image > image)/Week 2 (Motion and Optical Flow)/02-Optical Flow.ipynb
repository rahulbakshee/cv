{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "proper-founder",
   "metadata": {},
   "source": [
    "# Part 1: Low Level Vision (image > image)\n",
    "> ## Week 2 (Motion and Optical Flow)\n",
    ">> **02-Optical Flow**\n",
    "\n",
    "This is the curriculum for \"Learn Computer Vision\" by Siraj Raval on Youtube\n",
    "https://github.com/llSourcell/Learn_Computer_Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-secret",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "Optical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movement of object or camera. It is 2D vector field where each vector is a displacement vector showing the movement of points from first frame to second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image credits: http://en.wikipedia.org/wiki/Optical_flow\n",
    "plt.imshow(cv2.imread(\"optical_flow_basic1.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-playing",
   "metadata": {},
   "source": [
    "It shows a ball moving in 5 consecutive frames. The arrow shows its displacement vector. Optical flow has many applications in areas like :\n",
    "\n",
    "- Structure from Motion\n",
    "- Video Compression\n",
    "- Video Stabilization ...\n",
    "\n",
    "\n",
    "Optical flow works on several assumptions:\n",
    "\n",
    "- The pixel intensities of an object do not change between consecutive frames.\n",
    "- Neighbouring pixels have similar motion.\n",
    "\n",
    "\n",
    "Consider a pixel `I(x,y,t)` in first frame (Check a new dimension, time, is added here. Earlier we were working with images only, so no need of time). It moves by distance `(dx,dy)` in next frame taken after `dt` time. So since those pixels are the same and intensity does not change, we can say,\n",
    "\n",
    "$ I(x,y,t) =I(x+dx,y+dy,t+dt) $\n",
    "\n",
    "\n",
    "Then take taylor series approximation of right-hand side, remove common terms and divide by dt to get the following equation:\n",
    "\n",
    "$ f_x u + f_y v + ft = 0 $\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "$ f_x = ∂f/∂x ; fy = ∂f/∂y $\n",
    "\n",
    "\n",
    "$ u = dx/dt ; v = dy/dt $\n",
    "\n",
    "Above equation is called `Optical Flow` equation. In it, we can find `fx` and `fy`, they are image gradients. Similarly `ft` is the gradient along time. But `(u,v)` is unknown. We cannot solve this one equation with two unknown variables. So several methods are provided to solve this problem and one of them is Lucas-Kanade.\n",
    "\n",
    "\n",
    "# Lucas-Kanade method\n",
    "We have seen an assumption before, that all the neighbouring pixels will have similar motion. Lucas-Kanade method takes a 3x3 patch around the point. So all the 9 points have the same motion. We can find `(fx,fy,ft)` for these 9 points. So now our problem becomes solving 9 equations with two unknown variables which is over-determined. A better solution is obtained with least square fit method. Below is the final solution which is two equation-two unknown problem and solve to get the solution.\n",
    "\n",
    "So from the user point of view, the idea is simple, we give some points to track, we receive the optical flow vectors of those points. But again there are some problems. Until now, we were dealing with small motions, so it fails when there is a large motion. To deal with this we use pyramids. When we go up in the pyramid, small motions are removed and large motions become small motions. So by applying Lucas-Kanade there, we get optical flow along with the scale.\n",
    "\n",
    "\n",
    "OpenCV provides all these in a single function, `cv.calcOpticalFlowPyrLK()`. Here, we create a simple application which tracks some points in a video. To decide the points, we use `cv.goodFeaturesToTrack()`. We take the first frame, detect some `Shi-Tomasi corner points` in it, then we iteratively track those points using `Lucas-Kanade optical flow`. For the function `cv.calcOpticalFlowPyrLK()` we pass the previous frame, previous points and next frame. It returns next points along with some status numbers which has a value of 1 if next point is found, else zero. We iteratively pass these next points as previous points in next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-warehouse",
   "metadata": {},
   "source": [
    "### reading from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    # camera capture gives a return value(True/ False) and a frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the `q` key is pressed, break from the lop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "# release the camera if not done previously\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-single",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mighty-banks",
   "metadata": {},
   "source": [
    "### reading the video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# video credits: https://pixabay.com/videos/car-road-transportation-vehicle-2165/\n",
    "cap = cv2.VideoCapture(\"Car - 2165.mp4\")\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while True:\n",
    "    # camera capture gives a return value(True/ False) and a frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret or frame is None:\n",
    "        break\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite('sparse_opt_flow.png',img)\n",
    "# release the camera if not done previously\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-ladder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "national-helicopter",
   "metadata": {},
   "source": [
    "# Dense Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-distinction",
   "metadata": {},
   "source": [
    "Lucas-Kanade method computes optical flow for a sparse feature set (in our example, corners detected using Shi-Tomasi algorithm). OpenCV provides another algorithm to find the dense optical flow. It computes the optical flow for all the points in the frame. It is based on Gunner Farneback's algorithm which is explained in \"Two-Frame Motion Estimation Based on Polynomial Expansion\" by Gunner Farneback in 2003.\n",
    "\n",
    "Below sample shows how to find the dense optical flow using above algorithm. We get a 2-channel array with optical flow vectors, (u,v). We find their magnitude and direction. We color code the result for better visualization. Direction corresponds to Hue value of the image. Magnitude corresponds to Value plane. See the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# video credits: https://pixabay.com/videos/traffic-car-highway-street-27260/\n",
    "cap = cv2.VideoCapture(cv2.samples.findFile(\"Traffic - 27260.mp4\"))\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    cv2.imshow('frame2',bgr)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('opticalfb.png',frame2)\n",
    "        cv2.imwrite('opticalhsv.png',bgr)\n",
    "\n",
    "    prvs = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-flood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resident-donna",
   "metadata": {},
   "source": [
    "### references:\n",
    "- https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "- https://www.geeksforgeeks.org/python-opencv-dense-optical-flow/\n",
    "- https://www.geeksforgeeks.org/python-opencv-optical-flow-with-lucas-kanade-method/\n",
    "- https://learnopencv.com/optical-flow-in-opencv/\n",
    "- https://learnopencv.com/tag/optical-flow/\n",
    "- https://nanonets.com/blog/optical-flow/\n",
    "- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
